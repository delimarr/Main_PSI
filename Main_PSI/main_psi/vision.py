# Autor: Simon Eich
# File with the logic of the actual visin System.

import time

import cv2
import numpy as np

# Import the global variable from the globals module
global indices
from main_psi.globals import camera_index, indices

camera_index = 0
vision_data = []

# indices = []
passed = 0
missed = []
jumped = 0


def get_vision_data_func(indices):
    filename = "txt/config.txt"
    # image_path = f'Studie/img/img30.jpg' #used for tests when the camera is not available

    # Patameters for the line, mask center movement and Changing of the Radius
    line_thickness = 4
    center_move_x = 7
    center_move_y = 3
    var_radius = 2

    # Parameters for square detection
    min_square_size = 2000  # Minimum area of the square
    max_square_size = 4000  # Maximum area of the square

    def capture_picture(camera_index):
        # Initialize the camera
        cap = cv2.VideoCapture(camera_index)

        # Check if the camera opened successfully
        if not cap.isOpened():
            raise Exception(f"Could not open camera with index {camera_index}")

        # Capture a single frame
        ret, frame = cap.read()

        # Release the camera
        cap.release()

        # Check if the frame was captured successfully
        if not ret:
            raise Exception("Failed to capture image")

        return frame

    def find_circle(image):
        # Read the image
        image = frame
        # image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Apply a Gaussian blur to the image to reduce noise and improve circle detection
        blurred = cv2.GaussianBlur(gray, (9, 9), 2)

        # Use the Hough Circle Transform to detect circles
        circles = cv2.HoughCircles(
            blurred,
            cv2.HOUGH_GRADIENT,
            dp=1.2,
            minDist=100,
            param1=50,
            param2=30,
            minRadius=150,
            maxRadius=350,
        )

        if circles is not None:
            circles = np.round(circles[0, :]).astype("int")
            for x, y, r in circles:
                center = (x, y)
                radius = r
                break  # Consider only the first detected circle

            # Create a mask to isolate the circle
            mask = np.zeros_like(gray)
            cv2.circle(
                mask, center, radius + 2, 255, -1
            )  # Draw a filled white circle on the mask

            # Extract the circular region from the image
            circular_region = cv2.bitwise_and(image, image, mask=mask)
            # Convert the circular region to grayscale
            circular_region_gray = cv2.cvtColor(circular_region, cv2.COLOR_BGR2GRAY)

            # Convert the modified circular region to grayscale
            circular_region_mono = cv2.cvtColor(circular_region, cv2.COLOR_BGR2GRAY)
            circular_region_mono_colored = cv2.cvtColor(
                circular_region_mono, cv2.COLOR_GRAY2BGR
            )  # Convert back to BGR

            # Create an inverted mask to make the outside white
            inverted_mask = cv2.bitwise_not(mask)
            # Create a white background image
            white_background = np.full_like(image, 255)

            # Combine the monochrome circular region with the white background using the mask
            circle_image = cv2.bitwise_and(
                circular_region_mono_colored, circular_region_mono_colored, mask=mask
            ) + cv2.bitwise_and(white_background, white_background, mask=inverted_mask)

        else:
            print("Error: No circles detected.")

        return circle_image, center, radius, image

    def black_image(image):
        # Create a black background image
        black_image = image.copy()
        height, width, channels = black_image.shape
        black_image = np.zeros((height, width, channels), dtype=np.uint8)

        return black_image

    def line_image_preparation(circle_image):
        # Prepare the image that a successful line detection is possible.
        image_line = circle_image.copy()
        # image_line = np.zeros_like(circle_image)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Use the Canny edge detector
        edges = cv2.Canny(image_line, 50, 150, apertureSize=3)
        # Dilate
        dilated_edges = cv2.dilate(edges, None, iterations=1)

        # finde alle Ã¤usseren Konturen und markiere diese im Bild
        cnts, hir = cv2.findContours(
            dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        # Dilate
        dilated_edges = cv2.dilate(edges, None, iterations=1)
        cv2.drawContours(dilated_edges, cnts, -1, (0, 0, 0), 2)
        blur = cv2.GaussianBlur(dilated_edges, (21, 21), 2)
        line_search_image = cv2.dilate(blur, None, iterations=1)
        threshold_value = 128  # Modify if you want a different threshold
        _, line_search_image = cv2.threshold(
            line_search_image, threshold_value, 255, cv2.THRESH_BINARY
        )

        return line_search_image, dilated_edges

    def find_lines(line_search_image):
        lines = cv2.HoughLines(
            line_search_image, rho=1, theta=np.pi / 10, threshold=220
        )
        # Draw detected lines
        if lines is not None:
            for rho, theta in lines[:, 0]:
                a = np.cos(theta)
                b = np.sin(theta)
                x0 = a * rho
                y0 = b * rho
                x1 = int(x0 + 1000 * (-b))
                y1 = int(y0 + 1000 * (a))
                x2 = int(x0 - 1000 * (-b))
                y2 = int(y0 - 1000 * (a))
                cv2.line(
                    black_image, (x1, y1), (x2, y2), (255, 255, 255), line_thickness
                )
                cv2.line(
                    black_image, (x1, y1), (x2, y2), (255, 255, 255), line_thickness
                )
        black_image_white_lines = black_image.copy()

        return black_image_white_lines, lines

    def find_last_line(white_black_lines, dilated_edges, black_image):
        black_image_background = image.copy()
        height, width, channels = black_image_background.shape
        black_image_background = np.zeros((height, width, channels), dtype=np.uint8)

        def filter_lines_by_length_and_orientation(
            lines, max_length, vertical_threshold
        ):
            """Filter lines by maximum length and ensure they are approximately vertical."""
            filtered_lines = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
                # Check if the line is vertical
                if length <= max_length and abs(x2 - x1) <= vertical_threshold:
                    filtered_lines.append(line)
            return filtered_lines

        def find_leftmost_line(lines):
            """Find the line with the smallest x-coordinate."""
            leftmost_line = None
            min_x = float("inf")

            for line in lines:
                x1, y1, x2, y2 = line[0]
                # Calculate the smallest x-coordinate of the line
                line_min_x = min(x1, x2)
                if line_min_x < min_x:
                    min_x = line_min_x
                    leftmost_line = line
            return leftmost_line

        # Parameters for HoughLinesP
        threshold = 1  # Minimum number of intersections to detect a line
        minLineLength = 600  # Minimum length of a line segment
        maxLineGap = 10  # Maximum allowed gap between points on the same line
        maxLineLength = 1000  # Maximum length of line to be considered
        vertical_threshold = (
            1  # Threshold for vertical lines (difference in x-coordinates)
        )

        dilated_edges = cv2.dilate(dilated_edges, None, iterations=2)
        # Probabilistic Hough Line Transform
        lines = cv2.HoughLinesP(
            dilated_edges, 10, np.pi / 10, threshold, minLineLength, maxLineGap
        )
        # Filter lines by length and orientation
        filtered_lines = (
            filter_lines_by_length_and_orientation(
                lines, maxLineLength, vertical_threshold
            )
            if lines is not None
            else []
        )

        # Find the leftmost line
        leftmost_line = find_leftmost_line(filtered_lines)

        # Draw the leftmost line
        if leftmost_line is not None:
            x1, y1, x2, y2 = leftmost_line[0]
            cv2.line(
                black_image_background,
                (x1, y1),
                (x2, y2),
                (0, 255, 255),
                line_thickness,
            )

        white_black_lines = black_image
        black_image_background = cv2.cvtColor(
            black_image_background, cv2.COLOR_BGR2GRAY
        )

        lines = cv2.HoughLines(
            black_image_background, rho=1, theta=np.pi / 10, threshold=19
        )
        # Draw detected lines
        if lines is not None:
            for rho, theta in lines[:, 0]:
                a = np.cos(theta)
                b = np.sin(theta)
                x0 = a * rho
                y0 = b * rho
                x1 = int(x0 + 1000 * (-b))
                y1 = int(y0 + 1000 * (a))
                x2 = int(x0 - 1000 * (-b))
                y2 = int(y0 - 1000 * (a))
                cv2.line(
                    black_image,
                    (x1, y1),
                    (x2, y2),
                    (255, 255, 255),
                    line_thickness + 20,
                )

        return white_black_lines

    def circle_lines_SW(white_black_lines):
        new_center = (center[0] - center_move_x, center[1] - center_move_y)
        gray = cv2.cvtColor(white_black_lines, cv2.COLOR_BGR2GRAY)
        mask = np.zeros_like(gray)
        cv2.circle(
            mask, new_center, radius - var_radius, 255, -1
        )  # Draw a filled white circle on the mask
        circular_region = cv2.bitwise_and(
            white_black_lines, white_black_lines, mask=mask
        )

        return circular_region

    def change_background_to_white(circular_region):
        # Convert the image to grayscale
        gray = cv2.cvtColor(circular_region, cv2.COLOR_BGR2GRAY)

        # Apply a binary threshold to get a binary image
        _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)

        # Find contours in the binary image
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        if contours:
            # Assume the largest contour by area is the outer boundary
            largest_contour = max(contours, key=cv2.contourArea)

            # Create a mask for the largest contour
            mask = np.zeros_like(white_black_lines, dtype=np.uint8)
            cv2.drawContours(
                mask, [largest_contour], -1, (255, 255, 255), thickness=cv2.FILLED
            )

            # Change the background to white
            white_background = np.ones_like(image, dtype=np.uint8) * 255
            square_image = np.where(
                mask == (255, 255, 255), circular_region, white_background
            )
        else:
            print("No contours found in the image.")

        return square_image

    def is_square(contour, epsilon=0.04):
        peri = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon * peri, True)
        if len(approx) == 4:
            return True, approx
        return False, None

    def detect_squares(square_image, min_square_size, max_square_size, indices):
        gray = cv2.cvtColor(square_image, cv2.COLOR_BGR2GRAY)

        # Apply Gaussian blur
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # Apply Canny edge detection
        edged = cv2.Canny(blurred, 50, 150)

        # Find contours
        contours, _ = cv2.findContours(
            edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        squares = []
        centers_squares = []
        angle_array = []

        for contour in contours:
            is_square_contour, approx = is_square(contour)
            if is_square_contour:
                area = cv2.contourArea(contour)
                if min_square_size <= area <= max_square_size:
                    # Get the bounding box
                    (x, y, w, h) = cv2.boundingRect(approx)
                    # Find the center
                    cx = int(x + w / 2)
                    cy = int(y + h / 2)

                    # Calculate the angle
                    rect = cv2.minAreaRect(contour)
                    angle_point = 0  # rect[2]-90
                    angle_array.append(angle_point)

                    squares.append((approx, (cx, cy), (x, y, w, h)))
                    centers_squares.append((cx, cy))

        num_array = np.array(angle_array)
        angle = np.mean(num_array)
        angle = float(angle)
        # Sort squares by their top-left corner positions (reading order: top to bottom, left to right)
        squares.sort(key=lambda s: (s[2][0], -s[2][1]))

        # Draw the squares, their centers, and numbers
        for idx, (square, center, bbox) in enumerate(squares, start=1):
            x, y, w, h = bbox
            cv2.drawContours(image, [square], -1, (0, 0, 255), 2)
            cv2.circle(image, center, 5, (0, 0, 0), -1)

            positions = [index for index, value in enumerate(indices) if value == "1"]
            increased_positions = [x + 1 for x in indices]
            print(f"indicbbbies{increased_positions}")

            # Check if idx is in indices and set the color
            if idx in increased_positions:
                color = (0, 255, 0)  # Red color for indices in the list
            else:
                print(idx)
                color = (255, 0, 0)  # Yellow color for indices not in the list

            cv2.putText(
                image, str(idx), (x, y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2
            )

        # Draw the number
        # if idx == 2:
        #     cv2.putText(image, str(idx), (x, y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
        # else:
        #     cv2.putText(image, str(idx), (x, y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
        detect_squares_img = image.copy()

        num_center = len(centers_squares)
        # detect_squares_img = cv2.rotate(detect_squares_img, cv2.ROTATE_90_CLOCKWISE)

        # cv2.imshow("Detected Squares", detect_squares_img)

        return centers_squares, center, num_center, angle, detect_squares_img

    def read_config_file(filename):
        # getting the Matrix from the config file to do the coordinate transformation.
        points = []
        matrix = []
        transformed_p4 = None

        with open(filename) as file:
            lines = file.readlines()

            for line in lines:
                # Extract points (P1, P2, P3, P4)
                if line.startswith("P"):
                    parts = line.split(":")
                    point = tuple(map(int, parts[1].strip().split(",")))
                    points.append(point)

                # Extract the transformation matrix rows
                elif (
                    line.strip()
                    and not line.startswith("Transformation Matrix")
                    and not line.startswith("Transformed P4")
                    and not line.startswith("Time of configuration")
                ):
                    row = list(map(float, line.strip().split()))
                    matrix.append(row)

                # Extract transformed P4
                elif line.startswith("Transformed P4"):
                    parts = line.split(":")
                    transformed_p4 = tuple(map(float, parts[1].strip().split(",")))

        # Convert matrix to a NumPy array
        matrix = np.array(matrix, dtype=np.float32)

        return matrix

    def center_transformation(centers_squares, center, angle):
        vision_data_center = []

        def sort_tuples(arr):
            return sorted(arr, key=lambda x: (x[0], x[0]))

        # Sorting the arrays
        sorted_center_squares = sort_tuples(centers_squares)

        for i, (center) in enumerate(sorted_center_squares):
            point = sorted_center_squares[i]
            vision_data_center = apply_transformation(
                matrix, point, vision_data_center, angle
            )

        return vision_data_center

    def apply_transformation(matrix, point, vision_data_center, angle):
        pts = np.array([point], dtype=np.float32).reshape(-1, 1, 2)
        transformed_pts = cv2.transform(pts, matrix)

        # Extracting the numbers from the list
        numbers = transformed_pts[0][0]

        # Converting the np.float32 numbers to regular Python floats and rounding them
        rounded_values = (round(float(numbers[0]), 1), round(float(numbers[1]), 1))
        x = round(float(numbers[0]), 1)
        y = round(float(numbers[1]), 1)
        w = angle

        vision_data_center.append((x, y, w))

        return vision_data_center

    def filter_points_by_quality(coords, qual, center):
        # Check if both arrays have the same length
        if len(coords) != len(qual):
            # Filter points where quality is 1
            filtered_points = coords[qual == 1]
            print(filtered_points)

            for idx, (square, filtered_points, bbox) in enumerate(center, start=1):
                x, y, w, h = bbox
                cv2.drawContours(image, [square], -1, (0, 255, 0), 2)
                cv2.circle(image, center, 5, (0, 0, 255), -1)
                # Draw the number
                cv2.putText(
                    image,
                    str(idx),
                    (x, y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (255, 0, 0),
                    2,
                )

        return filtered_points

    # Analyze the provided image
    frame = capture_picture(camera_index)
    circle_image, center, radius, image = find_circle(frame)
    black_image = black_image(image)
    search_line_image, dilated_edges = line_image_preparation(circle_image)
    line_image = find_lines(search_line_image)
    white_black_lines = find_last_line(line_image, dilated_edges, black_image)
    circular_region = circle_lines_SW(white_black_lines)
    square_image = change_background_to_white(circular_region)
    (
        detect_squares_centers,
        center,
        num_center,
        angle,
        detect_squares_img,
    ) = detect_squares(square_image, min_square_size, max_square_size, indices)
    matrix = read_config_file(filename)
    # filtered_points = filter_points_by_quality(center, chip_quality_array, center) #The points are filtered later in the Karol Programm of the Robot. So it's not nessecary to do it here.

    if num_center == 36:
        vision_data = center_transformation(detect_squares_centers, center, angle)
        return vision_data, detect_squares_img, num_center
    else:
        print(f"The number of detected Chips is {num_center}")
        vision_data = center_transformation(detect_squares_centers, center, angle)

        return vision_data, detect_squares_img, num_center


indices = []


def get_vision_data(indices):
    indices = indices
    print
    num_center = 0
    i = 0
    # count_good=0
    # count_bad=0

    # The vision system doesn't have a succsrate dependig on the light about above 85%,
    # so we need to run the vision system multiple times to be sure to get the result in fast time.
    while num_center != 36 and i < 20:
        i += 1
        vision_data, detected_img, num_center = get_vision_data_func(indices)
        time.sleep(1)  # Delay for 1 seconds

    # Code can be used to get feedback how the detection is working.
    #    print(f'pic num: {i}-({num_center})')
    #    if num_center == 36:
    #        count_good+=1
    #    else:
    #        count_bad+=1
    # if i == 20:
    #    print('not right number found!')
    # print(f'gut:{count_good}')
    # print(f'schlecht:{count_bad}')
    #
    # if count_bad ==0:
    #    print('Perfect!')

    return vision_data, detected_img, num_center
